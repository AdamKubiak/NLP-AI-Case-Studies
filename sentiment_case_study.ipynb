{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'preprocessing' from 'c:\\\\Users\\\\kubia\\\\NLP-AI-Case-Studies\\\\preprocessing.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing as preproc\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "importlib.reload(preproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kubia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use preproc.prepare_imdb_data_csv only if you dont wanna use already prepared csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preproc.prepare_imdb_data_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentiment_imdb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over-powered mobile suits that can annihilate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a terrible movie that only gets worse ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an early film \"Pilot\" for the hit Cana...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Family Guy is THE best show on TV. EVER. It ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was China in this film. I choose the screen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Pretty good movie about a man and his wife who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>It was once suggested by Pauline Kael, never a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>The film notes describe the main role family, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I missed the full four hour version when it wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Sentiment\n",
       "0      Over-powered mobile suits that can annihilate ...          1\n",
       "1      This is a terrible movie that only gets worse ...          0\n",
       "2      This is an early film \"Pilot\" for the hit Cana...          1\n",
       "3      Family Guy is THE best show on TV. EVER. It ha...          1\n",
       "4      I was China in this film. I choose the screen ...          0\n",
       "...                                                  ...        ...\n",
       "49995  STAR RATING: ***** Saturday Night **** Friday ...          0\n",
       "49996  Pretty good movie about a man and his wife who...          1\n",
       "49997  It was once suggested by Pauline Kael, never a...          1\n",
       "49998  The film notes describe the main role family, ...          1\n",
       "49999  I missed the full four hour version when it wa...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Review', 'Sentiment']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przekształcanie słów w wektory cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład prezentujacy działanie klasy CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Codziennie pracuję przy komputerze w biurze.\",\n",
    "    \"Moje biuro jest nowoczesne i dobrze wyposażone.\",\n",
    "    \"Praca przy komputerze może być męcząca.\",\n",
    "    \"W biurze mamy spotkania codziennie rano.\",\n",
    "    \"Komputer w moim biurze jest bardzo szybki.\",\n",
    "    \"Lubię robić zakupy w dużych centrach handlowych.\",\n",
    "    \"W sklepie często znajduję promocje i zniżki.\",\n",
    "    \"Zakupy online są bardzo wygodne i szybkie.\",\n",
    "    \"Codziennie sprawdzam oferty w sklepach internetowych.\",\n",
    "    \"Moje ulubione sklepy mają zawsze szeroki wybór produktów.\",\n",
    "    \"Codziennie biegam w parku, aby utrzymać formę.\",\n",
    "    \"Bieganie jest moim ulubionym sposobem na relaks.\",\n",
    "    \"W parku często spotykam innych biegaczy.\",\n",
    "    \"Mój trener zaleca bieganie codziennie.\",\n",
    "    \"Codzienne bieganie pomaga mi w utrzymaniu zdrowia.\",\n",
    "    \"Komputer jest w moim biurze. Komputer działa bardzo szybko. Komputer jest nowoczesny.\",\n",
    "    \"Zakupy w sklepie są wygodne. Zakupy online są szybkie. Zakupy to moja ulubiona czynność.\",\n",
    "    \"Bieganie jest zdrowe. Bieganie codziennie poprawia kondycję. Bieganie w parku jest relaksujące.\"\n",
    "] # wygenerowane przy pomocy ChatGPT\n",
    "sentences_array = np.array(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprezentacja unigramowa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0] \n",
      "Liczba słów reprezentowana przez wektor:  5\n",
      "{'codziennie': 10, 'pracuję': 43, 'przy': 46, 'komputerze': 22, 'biurze': 6, 'moje': 30, 'biuro': 5, 'jest': 20, 'nowoczesne': 35, 'dobrze': 13, 'wyposażone': 72, 'praca': 42, 'może': 31, 'być': 7, 'męcząca': 33, 'mamy': 26, 'spotkania': 55, 'rano': 47, 'komputer': 21, 'moim': 28, 'bardzo': 1, 'szybki': 59, 'lubię': 24, 'robić': 50, 'zakupy': 73, 'dużych': 14, 'centrach': 8, 'handlowych': 17, 'sklepie': 52, 'często': 12, 'znajduję': 78, 'promocje': 45, 'zniżki': 79, 'online': 38, 'są': 62, 'wygodne': 71, 'szybkie': 60, 'sprawdzam': 57, 'oferty': 37, 'sklepach': 51, 'internetowych': 19, 'ulubione': 66, 'sklepy': 53, 'mają': 25, 'zawsze': 75, 'szeroki': 58, 'wybór': 70, 'produktów': 44, 'biegam': 3, 'parku': 39, 'aby': 0, 'utrzymać': 69, 'formę': 16, 'bieganie': 4, 'ulubionym': 67, 'sposobem': 54, 'na': 34, 'relaks': 48, 'spotykam': 56, 'innych': 18, 'biegaczy': 2, 'mój': 32, 'trener': 64, 'zaleca': 74, 'codzienne': 9, 'pomaga': 40, 'mi': 27, 'utrzymaniu': 68, 'zdrowia': 77, 'działa': 15, 'szybko': 61, 'nowoczesny': 36, 'to': 63, 'moja': 29, 'ulubiona': 65, 'czynność': 11, 'zdrowe': 76, 'poprawia': 41, 'kondycję': 23, 'relaksujące': 49}\n"
     ]
    }
   ],
   "source": [
    "countVec = CountVectorizer()\n",
    "bag = countVec.fit_transform(sentences_array)\n",
    "print(bag.toarray()[0], '\\nLiczba słów reprezentowana przez wektor: ' ,bag.toarray()[0].sum())\n",
    "print(countVec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprezentacja 2-gramowa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
      "Liczba słów reprezentowana przez wektor:  4\n",
      "{'codziennie pracuję': 18, 'pracuję przy': 60, 'przy komputerze': 62, 'komputerze biurze': 36, 'moje biuro': 46, 'biuro jest': 9, 'jest nowoczesne': 29, 'nowoczesne dobrze': 51, 'dobrze wyposażone': 23, 'praca przy': 59, 'komputerze może': 37, 'może być': 48, 'być męcząca': 13, 'biurze mamy': 12, 'mamy spotkania': 41, 'spotkania codziennie': 69, 'codziennie rano': 19, 'komputer moim': 35, 'moim biurze': 43, 'biurze jest': 10, 'jest bardzo': 27, 'bardzo szybki': 1, 'lubię robić': 39, 'robić zakupy': 63, 'zakupy dużych': 88, 'dużych centrach': 24, 'centrach handlowych': 14, 'sklepie często': 65, 'często znajduję': 22, 'znajduję promocje': 95, 'promocje zniżki': 61, 'zakupy online': 89, 'online są': 53, 'są bardzo': 75, 'bardzo wygodne': 3, 'wygodne szybkie': 86, 'codziennie sprawdzam': 20, 'sprawdzam oferty': 71, 'oferty sklepach': 52, 'sklepach internetowych': 64, 'moje ulubione': 47, 'ulubione sklepy': 81, 'sklepy mają': 67, 'mają zawsze': 40, 'zawsze szeroki': 93, 'szeroki wybór': 72, 'wybór produktów': 85, 'codziennie biegam': 16, 'biegam parku': 4, 'parku aby': 54, 'aby utrzymać': 0, 'utrzymać formę': 84, 'bieganie jest': 6, 'jest moim': 28, 'moim ulubionym': 44, 'ulubionym sposobem': 82, 'sposobem na': 68, 'na relaks': 50, 'parku często': 55, 'często spotykam': 21, 'spotykam innych': 70, 'innych biegaczy': 26, 'mój trener': 49, 'trener zaleca': 79, 'zaleca bieganie': 92, 'bieganie codziennie': 5, 'codzienne bieganie': 15, 'bieganie pomaga': 8, 'pomaga mi': 57, 'mi utrzymaniu': 42, 'utrzymaniu zdrowia': 83, 'komputer jest': 34, 'biurze komputer': 11, 'komputer działa': 33, 'działa bardzo': 25, 'bardzo szybko': 2, 'szybko komputer': 74, 'jest nowoczesny': 30, 'zakupy sklepie': 90, 'sklepie są': 66, 'są wygodne': 77, 'wygodne zakupy': 87, 'są szybkie': 76, 'szybkie zakupy': 73, 'zakupy to': 91, 'to moja': 78, 'moja ulubiona': 45, 'ulubiona czynność': 80, 'jest zdrowe': 32, 'zdrowe bieganie': 94, 'codziennie poprawia': 17, 'poprawia kondycję': 58, 'kondycję bieganie': 38, 'bieganie parku': 7, 'parku jest': 56, 'jest relaksujące': 31}\n"
     ]
    }
   ],
   "source": [
    "countVec2 = CountVectorizer(ngram_range=(2,2))\n",
    "bag2 = countVec2.fit_transform(sentences_array)\n",
    "print(bag2.toarray()[0], '\\nLiczba słów reprezentowana przez wektor: ' ,bag2.toarray()[0].sum())\n",
    "print(countVec2.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprezentację, którą należy wybrać zależy od typu zadania z którym się borykamy, \n",
    "przykładowo prof. Kanaris dowiedli że n-gramy o rozmiarze 3 lub 4 dają bardzo dobre wyniki dla rozwiązania problemu wykrycia spamu poczty e-mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Słowa często występujące w wielu różnych danych tekstowych bardzo często nie niosą za sobą rozróżniających informacji. Aby zmniejszyć wpływ takich słów na uczenie modelu możemy wykorzystać **ważenie częstości termów**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.63832904,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.1821154 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.39232468, 0.        , 0.        , 0.29627309, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.23311024,\n",
       "       0.        , 0.29627309, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.29627309,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.29627309, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfTransformer(use_idf = True, norm = 'l2', smooth_idf=True)\n",
    "tfidf.fit_transform(countVec.fit_transform(sentences_array)).toarray()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One reasons why they call the 80's, \"The Awesome 80's\" is quality television. Shows like the Wonder Years, War of the Worlds (the series), V, Amazing Stories, and many more have always left an impression to each \"fortunate\" one of us that in time will always find a way to reawaken itself. To top that, here comes Monsters! A series quite unique of its own, and a theme fully dedicate to - monsters. May it be the good, the bad, and the morbid.<br /><br />If you're a fan of classic shows or if you have the fascination of horror films then this one is absolutely for you. Provided you can find this rare gem. <br /><br />Even the newer generations will be in awe with some of the episode with its grittiness, it's indiscriminating use of gore effects or its story telling power and simplicity. I guarantee, because I'm 23 :).<br /><br />Be sure NOT to miss this!<br /><br />Although, it's a show seemingly forgotten by the modern world, it will always be with those who can always remember...\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Review'].str.contains(r\":\\)\")]['Review'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this movie is a perfect example of barkers cinematic gifts to the horror monster genre i thought this movie did a great job of keeping the feel and look of the novella and comic books or actually the comics may have come second i forget this movie was made for barker fans it helps to have read the book beforehand but isn t that important if you can follow a film i saw to anyone who is on the fence about this film read the book then re watch the film you might find a new respect for the movie i came to this movie a big fan of barker already and having read the book prior loved the film instantly there are great cameos makeup writing directing etc in this film this movie does something that most monster horror movies fail miserably at show the monsters they are there in full color not hidden in shadows and taking most of the screen time unlike other films that use quick cuts or trick lighting to hide the creature this movie celebrates the grotesque and casts them into the forefront as the good guy two thumbs up clive we re waiting for the thief of always :)'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = preproc.regex_preprocessing(df[df['Review'].str.contains(r\":\\)\")]['Review'].iloc[0])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(preproc.regex_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i went and saw this movie last night after being coaxed to by a few friends of mine i ll admit that i was reluctant to see it because from what i knew of ashton kutcher he was only able to do comedy i was wrong kutcher played the character of jake fischer very well and kevin costner played ben randall with such professionalism the sign of a good movie is that it can toy with our emotions this one did exactly that the entire theater which was sold out was overcome by laughter during the first half of the movie and were moved to tears during the second half while exiting the theater i not only saw many women in tears but many full grown men as well trying desperately not to let anyone see them crying this movie was great and i suggest that you go see it before you judge'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['went',\n",
       " 'saw',\n",
       " 'movi',\n",
       " 'last',\n",
       " 'night',\n",
       " 'coax',\n",
       " 'friend',\n",
       " 'mine',\n",
       " 'admit',\n",
       " 'reluct',\n",
       " 'see',\n",
       " 'knew',\n",
       " 'ashton',\n",
       " 'kutcher',\n",
       " 'abl',\n",
       " 'comedi',\n",
       " 'wrong',\n",
       " 'kutcher',\n",
       " 'play',\n",
       " 'charact',\n",
       " 'jake',\n",
       " 'fischer',\n",
       " 'well',\n",
       " 'kevin',\n",
       " 'costner',\n",
       " 'play',\n",
       " 'ben',\n",
       " 'randal',\n",
       " 'profession',\n",
       " 'sign',\n",
       " 'good',\n",
       " 'movi',\n",
       " 'toy',\n",
       " 'emot',\n",
       " 'one',\n",
       " 'exactli',\n",
       " 'entir',\n",
       " 'theater',\n",
       " 'sold',\n",
       " 'overcom',\n",
       " 'laughter',\n",
       " 'first',\n",
       " 'half',\n",
       " 'movi',\n",
       " 'move',\n",
       " 'tear',\n",
       " 'second',\n",
       " 'half',\n",
       " 'exit',\n",
       " 'theater',\n",
       " 'saw',\n",
       " 'mani',\n",
       " 'women',\n",
       " 'tear',\n",
       " 'mani',\n",
       " 'full',\n",
       " 'grown',\n",
       " 'men',\n",
       " 'well',\n",
       " 'tri',\n",
       " 'desper',\n",
       " 'let',\n",
       " 'anyon',\n",
       " 'see',\n",
       " 'cri',\n",
       " 'movi',\n",
       " 'great',\n",
       " 'suggest',\n",
       " 'go',\n",
       " 'see',\n",
       " 'judg']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.tokenize_porter(df['Review'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor turned director bill paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i saw this film in a sneak preview and it is d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>towards the end of the movie i felt it was too...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>this is the kind of movie that my enemies cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i saw descent last night at the stockholm film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>some films that you pick up for a pound turn o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>this is one of the dumbest films i ve ever see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Sentiment\n",
       "0      i went and saw this movie last night after bei...          1\n",
       "1      actor turned director bill paxton follows up h...          1\n",
       "2      as a recreational golfer with some knowledge o...          1\n",
       "3      i saw this film in a sneak preview and it is d...          1\n",
       "4      bill paxton has taken the true story of the 19...          1\n",
       "...                                                  ...        ...\n",
       "49995  towards the end of the movie i felt it was too...          0\n",
       "49996  this is the kind of movie that my enemies cont...          0\n",
       "49997  i saw descent last night at the stockholm film...          0\n",
       "49998  some films that you pick up for a pound turn o...          0\n",
       "49999  this is one of the dumbest films i ve ever see...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train , y_test = train_test_split(df['Review'], df['Sentiment'], test_size=0.35, random_state=42, stratify=df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "240 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.8928     0.88876923 0.89326154 0.88907692\n",
      " 0.86449231 0.86424615 0.88021538 0.86427692        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.89455385 0.88990769 0.89618462 0.88953846 0.87393846 0.87587692\n",
      " 0.89609231 0.87569231        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.89009231 0.88249231\n",
      " 0.89307692 0.88310769 0.87646154 0.87772308 0.89806154 0.87815385\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.88147692 0.87753846 0.88273846 0.87738462\n",
      " 0.86378462 0.86784615 0.88950769 0.86787692        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87596923 0.86864615 0.87766154 0.86852308 0.86187692 0.86498462\n",
      " 0.88812308 0.8652            nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.8748     0.86495385\n",
      " 0.87806154 0.8652     0.85941538 0.86409231 0.88569231 0.86378462]\n",
      "  warnings.warn(\n",
      "c:\\Users\\kubia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;clf__C&#x27;: [1.0, 10.0, 50.0],\n",
       "                          &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;vect__ngram_range&#x27;: [(1, 1), (2, 2)],\n",
       "                          &#x27;vect__stop_words&#x27;: [[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                                &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;,\n",
       "                                                &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                &quot;you&#x27;ll&quot;, &quot;y...\n",
       "                                                &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;,\n",
       "                                                &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                                                &#x27;itself&#x27;, ...],\n",
       "                                               None],\n",
       "                          &#x27;vect__tokenizer&#x27;: [&lt;function tokenize at 0x000002CBBF177880&gt;,\n",
       "                                              &lt;function tokenize_porter at 0x000002CBDA186840&gt;],\n",
       "                          &#x27;vect__use_idf&#x27;: [False]}],\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;clf__C&#x27;: [1.0, 10.0, 50.0],\n",
       "                          &#x27;clf__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;vect__ngram_range&#x27;: [(1, 1), (2, 2)],\n",
       "                          &#x27;vect__stop_words&#x27;: [[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                                &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;,\n",
       "                                                &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                &quot;you&#x27;ll&quot;, &quot;y...\n",
       "                                                &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;,\n",
       "                                                &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                                &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                                &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                &quot;she&#x27;s&quot;, &#x27;her&#x27;, &#x27;hers&#x27;,\n",
       "                                                &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                                                &#x27;itself&#x27;, ...],\n",
       "                                               None],\n",
       "                          &#x27;vect__tokenizer&#x27;: [&lt;function tokenize at 0x000002CBBF177880&gt;,\n",
       "                                              &lt;function tokenize_porter at 0x000002CBDA186840&gt;],\n",
       "                          &#x27;vect__use_idf&#x27;: [False]}],\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(lowercase=False, ngram_range=(2, 2),\n",
       "                                 tokenizer=&lt;function tokenize at 0x000002CBBF177880&gt;)),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(C=50.0, random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(lowercase=False, ngram_range=(2, 2),\n",
       "                tokenizer=&lt;function tokenize at 0x000002CBBF177880&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=50.0, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__C': [1.0, 10.0, 50.0],\n",
       "                          'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__ngram_range': [(1, 1), (2, 2)],\n",
       "                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
       "                                                'our', 'ours', 'ourselves',\n",
       "                                                'you', \"you're\", \"you've\",\n",
       "                                                \"you'll\", \"y...\n",
       "                                                'our', 'ours', 'ourselves',\n",
       "                                                'you', \"you're\", \"you've\",\n",
       "                                                \"you'll\", \"you'd\", 'your',\n",
       "                                                'yours', 'yourself',\n",
       "                                                'yourselves', 'he', 'him',\n",
       "                                                'his', 'himself', 'she',\n",
       "                                                \"she's\", 'her', 'hers',\n",
       "                                                'herself', 'it', \"it's\", 'its',\n",
       "                                                'itself', ...],\n",
       "                                               None],\n",
       "                          'vect__tokenizer': [<function tokenize at 0x000002CBBF177880>,\n",
       "                                              <function tokenize_porter at 0x000002CBDA186840>],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
    "stop_words = stopwords.words('english')\n",
    "param_grid = [{'vect__ngram_range': [(1,1), (2,2)],\n",
    "               'vect__tokenizer': [preproc.tokenize,\n",
    "                                    preproc.tokenize_porter],\n",
    "               'vect__stop_words': [stop_words,None],\n",
    "                'clf__penalty': ['l1', 'l2'],\n",
    "                'clf__C': [1.0, 10.0, 50.0]},\n",
    "\n",
    "                {'vect__ngram_range': [(1,1), (2,2)],\n",
    "               'vect__tokenizer': [preproc.tokenize,\n",
    "                                    preproc.tokenize_porter],\n",
    "               'vect__stop_words': [stop_words,None],\n",
    "                'clf__penalty': ['l1', 'l2'],\n",
    "                'clf__C': [1.0, 10.0, 50.0],\n",
    "                'vect__use_idf': [False],\n",
    "                'vect__norm': [None]}]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring='accuracy', cv = 5, verbose=1, n_jobs = -1)\n",
    "\n",
    "gs_lr_tfidf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32500,) (17500,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 50.0,\n",
       " 'clf__penalty': 'l2',\n",
       " 'vect__ngram_range': (2, 2),\n",
       " 'vect__stop_words': None,\n",
       " 'vect__tokenizer': <function preprocessing.tokenize(text)>}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8980615384615385)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gs_lr_tfidf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9012"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26608429, 0.73391571]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([preproc.regex_preprocessing('Deadpool & Wolverine is enjoyable on its merits: R-rated, horribly violent juvenile fantasy loaded with nostalgic references from the glory days of comic reading that fans, new and old, will thoroughly enjoy as it drags you down to its irreverently funny level.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_model.joblib']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "joblib.dump(model, 'sentiment_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optymalizacja procesu uczenia za pomocą uczenia pozardzeniowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('sentiment_imdb_data.csv')\n",
    "#np.random.seed(1042)\n",
    "#df = df.reindex(np.random.permutation(df.index))\n",
    "#df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poczytaj o yield i next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'sentiment_imdb_data.csv'\n",
    "import csv\n",
    "def new_tokenizer(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text_array = [word for word in preproc.tokenize(preproc.regex_preprocessing(text)) if word not in stop_words]\n",
    "\n",
    "    return text_array\n",
    "\n",
    "def stream_csv(path):\n",
    "    with open(os.path.join(path), 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            text, label = row['Review'], int(row['Sentiment']) \n",
    "            yield text, label\n",
    "\n",
    "#next(stream_csv(csv_path))\n",
    "\n",
    "csv_stream = stream_csv(csv_path)\n",
    "\n",
    "def get_minibatch_from_file(stream_csv, batch_size):\n",
    "\n",
    "    X, y = [], []\n",
    "    try:\n",
    "        for _ in range(batch_size):\n",
    "            text, label = next(stream_csv)\n",
    "            X.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return X,y\n",
    "\n",
    "#get_minibatch_from_file(csv_stream, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traning phase: 100%|██████████| 45/45 [00:16<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from tqdm import tqdm\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=new_tokenizer)\n",
    "\n",
    "num_training_samples = 45000\n",
    "batch_size = 1000\n",
    "\n",
    "clf = SGDClassifier(loss='log_loss', random_state=42, max_iter=1)\n",
    "\n",
    "labels = np.array([0,1])\n",
    "\n",
    "for _ in tqdm(range(num_training_samples//batch_size), desc= 'Traning phase'):\n",
    "    X_train, y_train = get_minibatch_from_file(csv_stream, batch_size=batch_size)\n",
    "    if not X_train:\n",
    "        break\n",
    "\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=labels)\n",
    "\n",
    "remaining_samples = sum(1 for _ in csv_stream)\n",
    "if remaining_samples < 5000:\n",
    "    raise ValueError(\"Not enough samples left for testing after training.\")\n",
    "\n",
    "csv_stream = stream_csv(csv_path)\n",
    "\n",
    "for _ in range(num_training_samples):\n",
    "    next(csv_stream)\n",
    "\n",
    "X_test, y_test = get_minibatch_from_file(csv_stream, 5000)\n",
    "X_test = vect.transform(X_test)\n",
    "score = clf.score(X_test, y_test)\n",
    "\n",
    "print(f'Test Accuracy: {score:.4f}')\n",
    "\n",
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['improved_sentiment_model.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'improved_sentiment_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "result = clf.predict_proba(vect.transform(['When it debuted in 1991, Terminator 2: Judgment Day blew the collective minds of action movie junkies and, well, everyone who enjoys movies. What size this production has, what innovation, and what crowd-pleasing excitement. Marked by its breakthrough special effects, an unending series of bravura action sequences, and clever narrative inversion of the 1984 original, the production sells itself: Arnold Schwarzenegger, then at the height of his popularity, plays the good guy this time around, protecting the future’s rebel leader, John Connor, played by newcomer Edward Furlong. Linda Hamilton committed to her transformation into a ferocious survivalist and earned Oscar buzz for her performance. The new CGI technology renders an iconic movie villain, played by Robert Patrick, composed of liquid metal. And director James Cameron, in his prime after Aliens (1986) and The Abyss (1989), takes the scope far beyond what he achieved in the first, offering unexpected emotional value on top of his breakneck spectacle. T2 was the most expensive film ever made then, and it outperformed all box-office projections. This would be a trend for Cameron, which he would repeat with Titanic (1997) and his Avatar films. In its day, there was hardly a film more talked about or at the forefront of the zeitgeist than T2, and it would change the way blockbusters were made for the foreseeable future.']))\n",
    "\n",
    "print(1 if result[0][1]> 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(preproc.regex_preprocessing).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>over powered mobile suits that can annihilate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is a terrible movie that only gets worse ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is an early film pilot for the hit canadi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>family guy is the best show on tv ever it has ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was china in this film i choose the screen n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>star rating saturday night friday night friday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>pretty good movie about a man and his wife who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>it was once suggested by pauline kael never a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>the film notes describe the main role family a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>i missed the full four hour version when it wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Sentiment\n",
       "0      over powered mobile suits that can annihilate ...          1\n",
       "1      this is a terrible movie that only gets worse ...          0\n",
       "2      this is an early film pilot for the hit canadi...          1\n",
       "3      family guy is the best show on tv ever it has ...          1\n",
       "4      i was china in this film i choose the screen n...          0\n",
       "...                                                  ...        ...\n",
       "49995  star rating saturday night friday night friday...          0\n",
       "49996  pretty good movie about a man and his wife who...          1\n",
       "49997  it was once suggested by pauline kael never a ...          1\n",
       "49998  the film notes describe the main role family a...          1\n",
       "49999  i missed the full four hour version when it wa...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english', max_df=.1, max_features=5000)\n",
    "\n",
    "X_lda = count.fit_transform(df['Review'].values)\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = 10, random_state=123, learning_method='batch')\n",
    "\n",
    "X_topics = lda.fit_transform(X_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23347744e+01, 9.33925051e+01, 1.14651100e+02, ...,\n",
       "        1.16974583e+03, 8.20468598e+02, 3.99462945e+01],\n",
       "       [3.64806835e+00, 6.59362417e+00, 7.26364571e+01, ...,\n",
       "        1.00004698e-01, 1.00003597e-01, 6.08081320e-01],\n",
       "       [1.28972916e+00, 8.90783791e+01, 3.73251971e+01, ...,\n",
       "        1.00004863e-01, 1.00006898e-01, 3.69256345e+01],\n",
       "       ...,\n",
       "       [3.83353204e+01, 2.52100889e+02, 5.57809432e+01, ...,\n",
       "        1.43499961e-01, 2.91402865e-01, 1.24591309e+01],\n",
       "       [6.06510486e+01, 5.94358788e+01, 2.62038999e+02, ...,\n",
       "        5.01115935e+00, 1.77377000e+00, 1.26556788e+01],\n",
       "       [9.40935102e+00, 4.62148700e+01, 1.07270256e+02, ...,\n",
       "        1.00007048e-01, 1.00007233e-01, 1.00010660e-01]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temat 1.:\n",
      "horror effects budget low gore special blood scary dead monster\n",
      "Temat 2.:\n",
      "sex girl guy women feel kind maybe woman girls sure\n",
      "Temat 3.:\n",
      "war american history political german men country soldiers british government\n",
      "Temat 4.:\n",
      "wife father woman performance role mother murder husband plays son\n",
      "Temat 5.:\n",
      "series tv episode kids dvd comedy episodes remember shows watched\n",
      "Temat 6.:\n",
      "comedy star role original performance excellent fun effects wonderful fi\n",
      "Temat 7.:\n",
      "music beautiful family human cinema true art documentary children wonderful\n",
      "Temat 8.:\n",
      "town john car guy plays city goes jack later girl\n",
      "Temat 9.:\n",
      "worst minutes book script awful waste read terrible money stupid\n",
      "Temat 10.:\n",
      "action game music musical song version songs dvd dance fight\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "feature_names = count.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Temat %d.:\" % (topic_idx+1))\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words -1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "title zombie 3 1988 directors mostly lucio fulci but also claudio fragasso and bruno mattei cast ottaviano dellacqua massimo vani beatrice ring deran serafin review to review this flick and get some good background of it i gotta start by the beginning and the beginning of this is really george romer ...\n",
      "\n",
      "\n",
      "over christmas break a group of college friends stay behind to help prepare the dorms to be torn down and replaced by apartment buildings to make the work a bit more difficult a murderous chucks wearing psycho is wandering the halls of the dorm preying on the group in various violent ways registered ...\n",
      "\n",
      "\n",
      "fulci does this man brings one of the goriest and weirdest movies ever made answer yes cat in the brain also known as nightmare concert is fulci s last masterpiece yes it is no matter what some people will say about it there are few facts why this movie is one of the best fulci s movies fulci make a ...\n"
     ]
    }
   ],
   "source": [
    "horror = X_topics[:, 0].argsort()[::-1]\n",
    "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
    "    print('\\n')\n",
    "    print(df['Review'][movie_idx][:300], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned Topic: 1\n",
      "Topic Distribution: [0.94704468 0.00588364 0.00588368 0.00588474 0.00588393 0.00588369\n",
      " 0.00588362 0.00588387 0.00588413 0.00588402]\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"title zombie 3 1988 directors mostly lucio fulci but also claudio fragasso and bruno mattei cast ottaviano dellacqua massimo vani beatrice ring deran serafin review to review this flick and get some good background of it i gotta start by the beginning and the beginning of this is really george romer\"]  # Example new text\n",
    "\n",
    "\n",
    "new_X_lda = count.transform(new_text)\n",
    "\n",
    "new_X_topics = lda.transform(new_X_lda)\n",
    "\n",
    "assigned_topic = new_X_topics.argmax(axis=1)[0]\n",
    "\n",
    "print(\"Assigned Topic:\", assigned_topic + 1)\n",
    "print(\"Topic Distribution:\", new_X_topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
