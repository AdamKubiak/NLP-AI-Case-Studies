{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import preprocessing as preproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'sentiment_imdb_data.csv\\\\test\\\\pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpreproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_imdb_data_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentiment_imdb_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kubia\\OneDrive\\Pulpit\\notebooks\\preprocessing.py:17\u001b[0m, in \u001b[0;36mprepare_imdb_data_csv\u001b[1;34m(folder_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m neg_pos_folder \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_name, test_train_folder, neg_pos_folder)\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m txt_file \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading files in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_train_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneg_pos_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path,txt_file), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m neg_pos_folder \u001b[38;5;129;01min\u001b[39;00m label_dict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'sentiment_imdb_data.csv\\\\test\\\\pos'"
     ]
    }
   ],
   "source": [
    "df = preproc.prepare_imdb_data_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentiment_imdb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Sentiment\n",
       "0      I went and saw this movie last night after bei...          1\n",
       "1      Actor turned director Bill Paxton follows up h...          1\n",
       "2      As a recreational golfer with some knowledge o...          1\n",
       "3      I saw this film in a sneak preview, and it is ...          1\n",
       "4      Bill Paxton has taken the true story of the 19...          1\n",
       "...                                                  ...        ...\n",
       "49995  Towards the end of the movie, I felt it was to...          0\n",
       "49996  This is the kind of movie that my enemies cont...          0\n",
       "49997  I saw 'Descent' last night at the Stockholm Fi...          0\n",
       "49998  Some films that you pick up for a pound turn o...          0\n",
       "49999  This is one of the dumbest films, I've ever se...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przekształcanie słów w wektory cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład prezentujacy działanie klasy CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Codziennie pracuję przy komputerze w biurze.\",\n",
    "    \"Moje biuro jest nowoczesne i dobrze wyposażone.\",\n",
    "    \"Praca przy komputerze może być męcząca.\",\n",
    "    \"W biurze mamy spotkania codziennie rano.\",\n",
    "    \"Komputer w moim biurze jest bardzo szybki.\",\n",
    "    \"Lubię robić zakupy w dużych centrach handlowych.\",\n",
    "    \"W sklepie często znajduję promocje i zniżki.\",\n",
    "    \"Zakupy online są bardzo wygodne i szybkie.\",\n",
    "    \"Codziennie sprawdzam oferty w sklepach internetowych.\",\n",
    "    \"Moje ulubione sklepy mają zawsze szeroki wybór produktów.\",\n",
    "    \"Codziennie biegam w parku, aby utrzymać formę.\",\n",
    "    \"Bieganie jest moim ulubionym sposobem na relaks.\",\n",
    "    \"W parku często spotykam innych biegaczy.\",\n",
    "    \"Mój trener zaleca bieganie codziennie.\",\n",
    "    \"Codzienne bieganie pomaga mi w utrzymaniu zdrowia.\",\n",
    "    \"Komputer jest w moim biurze. Komputer działa bardzo szybko. Komputer jest nowoczesny.\",\n",
    "    \"Zakupy w sklepie są wygodne. Zakupy online są szybkie. Zakupy to moja ulubiona czynność.\",\n",
    "    \"Bieganie jest zdrowe. Bieganie codziennie poprawia kondycję. Bieganie w parku jest relaksujące.\"\n",
    "] # wygenerowane przy pomocy ChatGPT\n",
    "sentences_array = np.array(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprezentacja unigramowa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0] \n",
      "Liczba słów reprezentowana przez wektor:  5\n",
      "{'codziennie': 10, 'pracuję': 43, 'przy': 46, 'komputerze': 22, 'biurze': 6, 'moje': 30, 'biuro': 5, 'jest': 20, 'nowoczesne': 35, 'dobrze': 13, 'wyposażone': 72, 'praca': 42, 'może': 31, 'być': 7, 'męcząca': 33, 'mamy': 26, 'spotkania': 55, 'rano': 47, 'komputer': 21, 'moim': 28, 'bardzo': 1, 'szybki': 59, 'lubię': 24, 'robić': 50, 'zakupy': 73, 'dużych': 14, 'centrach': 8, 'handlowych': 17, 'sklepie': 52, 'często': 12, 'znajduję': 78, 'promocje': 45, 'zniżki': 79, 'online': 38, 'są': 62, 'wygodne': 71, 'szybkie': 60, 'sprawdzam': 57, 'oferty': 37, 'sklepach': 51, 'internetowych': 19, 'ulubione': 66, 'sklepy': 53, 'mają': 25, 'zawsze': 75, 'szeroki': 58, 'wybór': 70, 'produktów': 44, 'biegam': 3, 'parku': 39, 'aby': 0, 'utrzymać': 69, 'formę': 16, 'bieganie': 4, 'ulubionym': 67, 'sposobem': 54, 'na': 34, 'relaks': 48, 'spotykam': 56, 'innych': 18, 'biegaczy': 2, 'mój': 32, 'trener': 64, 'zaleca': 74, 'codzienne': 9, 'pomaga': 40, 'mi': 27, 'utrzymaniu': 68, 'zdrowia': 77, 'działa': 15, 'szybko': 61, 'nowoczesny': 36, 'to': 63, 'moja': 29, 'ulubiona': 65, 'czynność': 11, 'zdrowe': 76, 'poprawia': 41, 'kondycję': 23, 'relaksujące': 49}\n"
     ]
    }
   ],
   "source": [
    "countVec = CountVectorizer()\n",
    "bag = countVec.fit_transform(sentences_array)\n",
    "print(bag.toarray()[0], '\\nLiczba słów reprezentowana przez wektor: ' ,bag.toarray()[0].sum())\n",
    "print(countVec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprezentacja 2-gramowa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
      "Liczba słów reprezentowana przez wektor:  4\n",
      "{'codziennie pracuję': 18, 'pracuję przy': 60, 'przy komputerze': 62, 'komputerze biurze': 36, 'moje biuro': 46, 'biuro jest': 9, 'jest nowoczesne': 29, 'nowoczesne dobrze': 51, 'dobrze wyposażone': 23, 'praca przy': 59, 'komputerze może': 37, 'może być': 48, 'być męcząca': 13, 'biurze mamy': 12, 'mamy spotkania': 41, 'spotkania codziennie': 69, 'codziennie rano': 19, 'komputer moim': 35, 'moim biurze': 43, 'biurze jest': 10, 'jest bardzo': 27, 'bardzo szybki': 1, 'lubię robić': 39, 'robić zakupy': 63, 'zakupy dużych': 88, 'dużych centrach': 24, 'centrach handlowych': 14, 'sklepie często': 65, 'często znajduję': 22, 'znajduję promocje': 95, 'promocje zniżki': 61, 'zakupy online': 89, 'online są': 53, 'są bardzo': 75, 'bardzo wygodne': 3, 'wygodne szybkie': 86, 'codziennie sprawdzam': 20, 'sprawdzam oferty': 71, 'oferty sklepach': 52, 'sklepach internetowych': 64, 'moje ulubione': 47, 'ulubione sklepy': 81, 'sklepy mają': 67, 'mają zawsze': 40, 'zawsze szeroki': 93, 'szeroki wybór': 72, 'wybór produktów': 85, 'codziennie biegam': 16, 'biegam parku': 4, 'parku aby': 54, 'aby utrzymać': 0, 'utrzymać formę': 84, 'bieganie jest': 6, 'jest moim': 28, 'moim ulubionym': 44, 'ulubionym sposobem': 82, 'sposobem na': 68, 'na relaks': 50, 'parku często': 55, 'często spotykam': 21, 'spotykam innych': 70, 'innych biegaczy': 26, 'mój trener': 49, 'trener zaleca': 79, 'zaleca bieganie': 92, 'bieganie codziennie': 5, 'codzienne bieganie': 15, 'bieganie pomaga': 8, 'pomaga mi': 57, 'mi utrzymaniu': 42, 'utrzymaniu zdrowia': 83, 'komputer jest': 34, 'biurze komputer': 11, 'komputer działa': 33, 'działa bardzo': 25, 'bardzo szybko': 2, 'szybko komputer': 74, 'jest nowoczesny': 30, 'zakupy sklepie': 90, 'sklepie są': 66, 'są wygodne': 77, 'wygodne zakupy': 87, 'są szybkie': 76, 'szybkie zakupy': 73, 'zakupy to': 91, 'to moja': 78, 'moja ulubiona': 45, 'ulubiona czynność': 80, 'jest zdrowe': 32, 'zdrowe bieganie': 94, 'codziennie poprawia': 17, 'poprawia kondycję': 58, 'kondycję bieganie': 38, 'bieganie parku': 7, 'parku jest': 56, 'jest relaksujące': 31}\n"
     ]
    }
   ],
   "source": [
    "countVec2 = CountVectorizer(ngram_range=(2,2))\n",
    "bag2 = countVec2.fit_transform(sentences_array)\n",
    "print(bag2.toarray()[0], '\\nLiczba słów reprezentowana przez wektor: ' ,bag2.toarray()[0].sum())\n",
    "print(countVec2.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reprezentację, którą należy wybrać zależy od typu zadania z którym się borykamy, \n",
    "przykładowo prof. Kanaris dowiedli że n-gramy o rozmiarze 3 lub 4 dają bardzo dobre wyniki dla rozwiązania problemu wykrycia spamu poczty e-mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Słowa często występujące w wielu różnych danych tekstowych bardzo często nie niosą za sobą rozróżniających informacji. Aby zmniejszyć wpływ takich słów na uczenie modelu możemy wykorzystać **ważenie częstości termów**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.63832904,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.1821154 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.39232468, 0.        , 0.        , 0.29627309, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.23311024,\n",
       "       0.        , 0.29627309, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.29627309,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.29627309, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfTransformer(use_idf = True, norm = 'l2', smooth_idf=True)\n",
    "tfidf.fit_transform(countVec.fit_transform(sentences_array)).toarray()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19602</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45519</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25747</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42642</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45891</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42613</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43567</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Sentiment\n",
       "11841  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "19602  OK... so... I really like Kris Kristofferson a...          0\n",
       "45519  ***SPOILER*** Do not read this, if you think a...          0\n",
       "25747  hi for all the people who have seen this wonde...          1\n",
       "42642  I recently bought the DVD, forgetting just how...          0\n",
       "...                                                  ...        ...\n",
       "21243  OK, lets start with the best. the building. al...          0\n",
       "45891  The British 'heritage film' industry is out of...          0\n",
       "42613  I don't even know where to begin on this one. ...          0\n",
       "43567  Richard Tyler is a little boy who is scared of...          0\n",
       "2732   I waited long to watch this movie. Also becaus...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
